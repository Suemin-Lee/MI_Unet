{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "from tqdm import tqdm \n",
    "import keras\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "import utils\n",
    "import loggingreporter \n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "if not os.path.exists('plots/'):\n",
    "    os.mkdir('plots')\n",
    "\n",
    "from six.moves import cPickle\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "import kde\n",
    "import simplebinmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed = seed\n",
    "\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "TRAIN_PATH = 'stage1_train/'\n",
    "TEST_PATH = 'stage1_test/'\n",
    "\n",
    "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "test_ids = next(os.walk(TEST_PATH))[1]\n",
    "\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.int32)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.int32)\n",
    "Y_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.int32)\n",
    "\n",
    "\n",
    "# Which measure to plot\n",
    "infoplane_measure = 'upper'\n",
    "#infoplane_measure = 'bin'\n",
    "\n",
    "DO_SAVE        = True    # Whether to save plots or just show them\n",
    "DO_LOWER       = False    # (infoplane_measure == 'lower')   # Whether to compute lower bounds also\n",
    "DO_BINNED      = True    #(infoplane_measure == 'bin')     # Whether to compute MI estimates based on binning\n",
    "FULL_MI        = True\n",
    "DO_SAVE_GRAD   = True    \n",
    "\n",
    "\n",
    "MAX_EPOCHS = 10000     # Max number of epoch for which to compute mutual information measure\n",
    "COLORBAR_MAX_EPOCHS = MAX_EPOCHS\n",
    "\n",
    "# Directories from which to load saved layer activity\n",
    "ARCH ='128-64-32-16-8-16-32-64-10000'\n",
    "\n",
    "DIR_TEMPLATE = '%%s_%s'%ARCH\n",
    "\n",
    "# Functions to return upper and lower bounds on entropy of layer activity\n",
    "noise_variance = 2e-1                    # Added Gaussian noise variance\n",
    "Klayer_activity = K.placeholder(ndim=2)  # Keras placeholder \n",
    "entropy_func_upper = K.function([Klayer_activity,], [kde.entropy_estimator_kl(Klayer_activity, noise_variance),])\n",
    "entropy_func_lower = K.function([Klayer_activity,], [kde.entropy_estimator_bd(Klayer_activity, noise_variance),])\n",
    "\n",
    "# nats to bits conversion factor\n",
    "nats2bits = 1.0/np.log(2) \n",
    "\n",
    "\n",
    "PLOT_LAYERS    = None     # Which layers to plot.  If None, all saved layers are plotted \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data structure used to store results\n",
    "measures = OrderedDict()\n",
    "measures['relu'] = {}\n",
    "# measures['tanh'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Resizing image\n",
    "print('Resizing training images and masks for training')\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):   \n",
    "    path = TRAIN_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]  \n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img  #Fill empty X_train with values from img\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "        mask_ = imread(path + '/masks/' + mask_file)\n",
    "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant',  \n",
    "                                      preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, mask_)  \n",
    "            \n",
    "    Y_train[n] = mask   \n",
    "\n",
    "# test images\n",
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "print('Resizing test images and masks for testing') \n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = TEST_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "        mask_ = imread(path + '/masks/' + mask_file)\n",
    "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant',  \n",
    "                                      preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, mask_)  \n",
    "            \n",
    "    Y_test[n] = mask   \n",
    "\n",
    "print('Resizing images... Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization of the images\n",
    "X_train= X_train/255\n",
    "Y_train= Y_train/255\n",
    "X_test = X_test/255\n",
    "Y_test = Y_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "nb_classes=2**16;  #Total number of classifier types (2**16= 65,536) \n",
    "Dataset = namedtuple('Dataset',['X','Y','y','nb_classes'])\n",
    "\n",
    "y_train = Y_train\n",
    "y_test = Y_test\n",
    "\n",
    "trn = Dataset(X_train, Y_train, y_train, nb_classes)\n",
    "tst = Dataset(X_test , Y_test, y_test, nb_classes)\n",
    "\n",
    "y = tst.y\n",
    "Y = tst.Y\n",
    "\n",
    "if FULL_MI:\n",
    "    full = utils.construct_full_dataset(trn,tst)\n",
    "    y = full.y\n",
    "    Y = full.Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial coarsening methods \n",
    "\n",
    "# create classifier types\n",
    "mask = ((np.arange(2**16)[:,None] & (1 << np.arange(16))) != 0)\n",
    "classifer = mask.astype(int).reshape(-1,4,4)\n",
    "# coarsening output image into 4*4 pixel\n",
    "import skimage.measure\n",
    "import statistics\n",
    "\n",
    "division = 16\n",
    "thresholdT = 32*32/division #Threshold value\n",
    "\n",
    "# down sampling\n",
    "block_size = 32\n",
    "coarsening = skimage.measure.block_reduce(full.y[1], block_size =(block_size,block_size,1), func=np.sum)\n",
    "\n",
    "for i in range(full.y.shape[0]-1):\n",
    "    down_sample = full.y[i+1]\n",
    "    tmp = skimage.measure.block_reduce(down_sample, block_size =(block_size,block_size,1), func=np.sum)\n",
    "    coarsening = np.concatenate((coarsening, tmp))\n",
    "\n",
    "coarsening[coarsening <= thresholdT] = 0  # if the selected area is smaller than the thresholdT masks as zero\n",
    "coarsening[coarsening > thresholdT] = 1   # if the selected area is larger than the thresholdT masks as one\n",
    "\n",
    "coarsening = coarsening.reshape(full.y.shape[0],4,4)\n",
    "\n",
    "# Make 2d into 1d label\n",
    "y_1dim =[]\n",
    "for i in range(full.y.shape[0]):\n",
    "    tmp = coarsening[i] \n",
    "    for j in range(nb_classes):\n",
    "        if np.all(tmp == classifer[j]):\n",
    "            y_1dim.append(j)\n",
    "y_1dim = np.array(y_1dim)\n",
    "\n",
    "# label postion similar to MNIST data setting\n",
    "saved_labelixs = {}\n",
    "for i in range(nb_classes):\n",
    "    saved_labelixs[i] = y_1dim == i\n",
    "\n",
    "# calculate label probability P(Y=y) which needs for I(M;Y) (similar to MNIST data setting)\n",
    "labelprobs=[]\n",
    "for i in range(nb_classes):\n",
    "    tmp = sum(saved_labelixs[i])/(full.y.shape[0])\n",
    "    labelprobs.append(tmp)\n",
    "labelprobs = np.array(labelprobs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute Mutual Information (similar to MNIST data setting with different number of classifiers)\n",
    "\n",
    "for activation in measures.keys():\n",
    "\n",
    "    cur_dir = 'rawdata/' + DIR_TEMPLATE % activation\n",
    "    if not os.path.exists(cur_dir):\n",
    "        print(\"Directory %s not found\" % cur_dir)\n",
    "        continue\n",
    "        \n",
    "    # Load files saved during each epoch, and compute MI measures of the activity in that epoch\n",
    "    print('*** Doing %s ***' % cur_dir)\n",
    "    for epochfile in sorted(os.listdir(cur_dir)):\n",
    "        if not epochfile.startswith('epoch'):\n",
    "            continue\n",
    "        fname = cur_dir + \"/\" + epochfile\n",
    "        with open(fname, 'rb') as f:\n",
    "            d = cPickle.load(f)\n",
    "        \n",
    "            epoch = d['epoch']\n",
    "        if epoch in measures[activation]: # Skip this epoch if its already been processed\n",
    "            continue                      # this is a trick to allow us to rerun this cell multiple times)\n",
    "            \n",
    "        if epoch > MAX_EPOCHS:\n",
    "            continue\n",
    "\n",
    "        print(\"Doing\", fname)\n",
    "        \n",
    "        num_layers = len(d['data']['activity_tst'])\n",
    "        grad_mean = d['data']['gradmean']\n",
    "        grad_std = d['data']['gradstd']\n",
    "        \n",
    "        if PLOT_LAYERS is None:\n",
    "            PLOT_LAYERS = []\n",
    "            for lndx in range(num_layers):\n",
    "                #if d['data']['activity_tst'][lndx].shape[1] < 200 and lndx != num_layers - 1:\n",
    "                PLOT_LAYERS.append(lndx)\n",
    "\n",
    "        cepochdata = defaultdict(list)\n",
    "        for lndx in range(num_layers):\n",
    "            activity = d['data']['activity_tst'][lndx]\n",
    "   \n",
    "            if len(activity)>3: #if more than 2 dimensional change into 1 dimensional matrix (3D into 1D matrix)\n",
    "                                \n",
    "                activity=np.reshape(activity , [activity.shape[0] , -1])\n",
    "            \n",
    "            # Compute marginal entropies\n",
    "            h_upper = entropy_func_upper([activity,])[0]\n",
    "            if DO_LOWER:\n",
    "                h_lower = entropy_func_lower([activity,])[0]\n",
    "                \n",
    "            # Layer activity given input. This is simply the entropy of the Gaussian noise\n",
    "            hM_given_X = kde.kde_condentropy(activity, noise_variance)\n",
    "\n",
    "            # Compute conditional entropies of layer activity given output\n",
    "            hM_given_Y_upper=0.\n",
    "            for i in range(nb_classes):\n",
    "                data = activity[saved_labelixs[i],:]\n",
    "                if len(data)==0:\n",
    "                    hcond_upper =0\n",
    "                else: hcond_upper = entropy_func_upper([data,])[0]\n",
    "                hM_given_Y_upper += labelprobs[i] * hcond_upper\n",
    "\n",
    "            \n",
    "#             if DO_LOWER:\n",
    "#                 hM_given_Y_lower=0.\n",
    "#                 hM_given_Y_lower_ls=[]\n",
    "#                 for i in range(nb_classes):\n",
    "#                     hcond_lower = entropy_func_lower([activity[saved_labelixs[i],:],])[0]\n",
    "#                     hM_given_Y_lower += labelprobs[i] * hcond_lower\n",
    "        \n",
    "                \n",
    "            cepochdata['MI_XM_upper'].append( nats2bits * (h_upper - hM_given_X) )\n",
    "            cepochdata['MI_YM_upper'].append( nats2bits * (h_upper - hM_given_Y_upper) )\n",
    "            cepochdata['H_M_upper'  ].append( nats2bits * h_upper )\n",
    "\n",
    "            cepochdata['H_M_given_X_upper'].append( nats2bits * (hM_given_X) )\n",
    "            cepochdata['H_M_given_Y_upper'].append( nats2bits * (hM_given_Y_upper) )\n",
    "\n",
    "            pstr = 'upper: MI(X;M)=%0.3f, MI(Y;M)=%0.3f' % (cepochdata['MI_XM_upper'][-1], cepochdata['MI_YM_upper'][-1])\n",
    "            pstr += ' | Conditional : H(M|X)=%0.3f, H(M|Y)=%0.3f' % (cepochdata['H_M_given_X_upper'][-1], cepochdata['H_M_given_Y_upper'][-1])\n",
    "# \n",
    "#             if DO_LOWER:  # Compute lower bounds\n",
    "#                 cepochdata['MI_XM_lower'].append( nats2bits * (h_lower - hM_given_X) )\n",
    "#                 cepochdata['MI_YM_lower'].append( nats2bits * (h_lower - hM_given_Y_lower) )\n",
    "#                 cepochdata['H_M_lower'  ].append( nats2bits * h_lower )\n",
    "#                 pstr += ' | lower: MI(X;M)=%0.3f, MI(Y;M)=%0.3f' % (cepochdata['MI_XM_lower'][-1], cepochdata['MI_YM_lower'][-1])\n",
    "\n",
    "            if DO_BINNED: # Compute binning estimates\n",
    "                binxm, binym = simplebinmi.bin_calc_information2(saved_labelixs, activity, 0.1)\n",
    "                cepochdata['MI_XM_bin'].append( nats2bits * binxm )\n",
    "                cepochdata['MI_YM_bin'].append( nats2bits * binym )\n",
    "                pstr += ' | bin: MI(X;M)=%0.3f, MI(Y;M)=%0.3f' % (cepochdata['MI_XM_bin'][-1], cepochdata['MI_YM_bin'][-1])\n",
    "            \n",
    "            print('- Layer %d %s' % (lndx, pstr) )\n",
    "\n",
    "            \n",
    "        measures[activation][epoch] = cepochdata\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MI versus epochs Plots\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "gs = gridspec.GridSpec(4,2)\n",
    "for actndx, (activation, vals) in enumerate(measures.items()):\n",
    "    epochs = sorted(vals.keys())\n",
    "    if not len(epochs):\n",
    "        continue\n",
    "\n",
    "    \n",
    "    plt.subplot(gs[0,actndx])\n",
    "    for lndx, layerid in enumerate(PLOT_LAYERS):\n",
    "        xmvalsU = np.array([vals[epoch]['MI_XM_upper'][layerid] for epoch in epochs])\n",
    "        plt.plot(epochs, xmvalsU, label='Layer %d'%layerid)\n",
    "    plt.xscale('log')\n",
    "    plt.ylabel('I(X;M)')\n",
    "\n",
    "    \n",
    "    plt.subplot(gs[1,actndx])\n",
    "    for lndx, layerid in enumerate(PLOT_LAYERS):\n",
    "        YmvalsU = np.array([vals[epoch]['MI_YM_upper'][layerid] for epoch in epochs])\n",
    "        plt.plot(epochs, YmvalsU, label='Layer %d'%layerid)\n",
    "    plt.xscale('log')\n",
    "    plt.ylabel('I(Y;M)')\n",
    "    \n",
    "    plt.subplot(gs[2,actndx])\n",
    "    for lndx, layerid in enumerate(PLOT_LAYERS):\n",
    "        hbinnedvals = np.array([vals[epoch]['MI_XM_bin'][layerid] for epoch in epochs])\n",
    "        plt.semilogx(epochs, hbinnedvals, label='Layer %d'%layerid)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(\"I(X;M)bin\")\n",
    "\n",
    "    plt.subplot(gs[3,actndx])\n",
    "    for lndx, layerid in enumerate(PLOT_LAYERS):\n",
    "        hbinnedvals = np.array([vals[epoch]['MI_YM_bin'][layerid] for epoch in epochs])\n",
    "        plt.semilogx(epochs, hbinnedvals, label='Layer %d'%layerid)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(\"I(Y;M)bin\")\n",
    "    \n",
    "if DO_SAVE:\n",
    "    plt.savefig('plots/' + DIR_TEMPLATE % ('Epochs_over_MI_on_different_layers')+'.pdf',bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------ Modified infoplane 23 layers of 4*6 subplot  ------------  \n",
    "max_epoch = max( (max(vals.keys()) if len(vals) else 0) for vals in measures.values())\n",
    "sm = plt.cm.ScalarMappable(cmap='gnuplot', norm=plt.Normalize(vmin=0, vmax=COLORBAR_MAX_EPOCHS))\n",
    "sm._A = []\n",
    "\n",
    "\n",
    "fig=plt.figure(figsize=(12,8))\n",
    "for actndx, (activation, vals) in enumerate(measures.items()):\n",
    "    epochs = sorted(vals.keys())\n",
    "    if not len(epochs):\n",
    "        continue\n",
    "    for lndx, layerid in enumerate(PLOT_LAYERS):\n",
    "        xmvals=[]; ymvals=[]; c_save=[]\n",
    "        \n",
    "        if len(PLOT_LAYERS)>6:\n",
    "            if lndx<5:\n",
    "                plt.subplot(4,int(len(PLOT_LAYERS)/4)+1,lndx+1)   \n",
    "            elif lndx>3:\n",
    "                plt.subplot(4,int(len(PLOT_LAYERS)/4)+1,lndx+1)\n",
    "            \n",
    "            \n",
    "            for epoch in epochs:\n",
    "                c = sm.to_rgba(epoch)\n",
    "                xmval = np.array(vals[epoch]['MI_XM_'+infoplane_measure])[layerid]\n",
    "                ymval = np.array(vals[epoch]['MI_YM_'+infoplane_measure])[layerid]\n",
    "                xmvals.append(xmval)\n",
    "                ymvals.append(ymval)\n",
    "                c_save.append(c)\n",
    "                max_y = np.amax(ymval)\n",
    "                max_x = np.amax(xmval)\n",
    "                \n",
    "            for i,c in enumerate(c_save):\n",
    "                plt.plot(xmvals[i], ymvals[i], c=c, alpha=0.1, zorder=1)\n",
    "                plt.scatter(xmvals[i], ymvals[i], s=20, edgecolor='none', zorder=2,c=c)\n",
    "                plt.ylim([0, max_y+1])\n",
    "                plt.xlim([0, max_x+1])\n",
    "                plt.title(' Layer %1.0f'%(layerid+1),size=20)\n",
    "                if lndx%6==0:\n",
    "                    plt.ylabel('I(Y;M)',size=20)\n",
    "                if lndx>16:\n",
    "                    plt.xlabel('I(X;M)',size=20)\n",
    "\n",
    "                \n",
    "cbaxes = fig.add_axes([1.0, 0.125, 0.03, 0.8]) \n",
    "cb = plt.colorbar(sm, cax=cbaxes)\n",
    "cb.ax.tick_params(labelsize='large')\n",
    "cb.set_label(label='Epoch',size=20)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "if DO_SAVE:\n",
    "    plt.savefig('plots/' + DIR_TEMPLATE % ('Infoplane_layers_subplot')+'.pdf',bbox_inches='tight')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-shaped plot\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "max_epoch = max( (max(vals.keys()) if len(vals) else 0) for vals in measures.values())\n",
    "# sm = plt.cm.ScalarMappable(cmap='gnuplot', norm=plt.Normalize(vmin=0, vmax=COLORBAR_MAX_EPOCHS))\n",
    "sm = plt.cm.ScalarMappable(cmap='gnuplot',norm=LogNorm(vmin=1, vmax=COLORBAR_MAX_EPOCHS))\n",
    "sm._A = []\n",
    "\n",
    "\n",
    "fig=plt.figure(figsize=(8,4))\n",
    "for actndx, (activation, vals) in enumerate(measures.items()):\n",
    "    epochs = sorted(vals.keys())\n",
    "    c_save=[]\n",
    "    if len(epochs) <10: new_epochs = epochs\n",
    "    else : new_epochs= np.array([1,10,100,500,1000,2000,5000,9900])\n",
    "\n",
    "    for epoch in new_epochs:\n",
    "        c = sm.to_rgba(epoch)\n",
    "        c_save.append(c)\n",
    "        MI_XM = np.array([vals[epoch]['MI_XM_upper'][layerid] for lndx, layerid in enumerate(PLOT_LAYERS)])\n",
    "        MI_YM = np.array([vals[epoch]['MI_YM_upper'][layerid] for lndx, layerid in enumerate(PLOT_LAYERS)])\n",
    "        \n",
    "        plt.subplot(1,2,1)    \n",
    "        for i,c in enumerate(c_save):\n",
    "            plt.plot(PLOT_LAYERS, MI_XM, c=c, alpha=0.1, zorder=1)\n",
    "            plt.scatter(PLOT_LAYERS, MI_XM, s=20, edgecolor='none', zorder=2,c=c)\n",
    "            plt.ylabel('I (X;M)',size=18)\n",
    "            plt.xlabel('Layers',size=18)\n",
    "            plt.title('MI_XM_upper')\n",
    "\n",
    "        plt.subplot(1,2,2)    \n",
    "        for i,c in enumerate(c_save):\n",
    "            plt.plot(PLOT_LAYERS, MI_YM, c=c, alpha=0.1, zorder=1)\n",
    "            plt.scatter(PLOT_LAYERS, MI_YM, s=20, edgecolor='none', zorder=2,c=c)\n",
    "            plt.ylabel('I (Y;M)',size=18)\n",
    "            plt.xlabel('Layers',size=18)\n",
    "            plt.title('MI_YM_upper')\n",
    "            \n",
    "cbaxes = fig.add_axes([1.0, 0.125, 0.03, 0.8]) \n",
    "cb = plt.colorbar(sm, cax=cbaxes)\n",
    "cb.ax.tick_params(labelsize='large')\n",
    "cb.set_label(label='Epoch',size=18)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if DO_SAVE:\n",
    "    plt.savefig('plots/' + DIR_TEMPLATE % ('U_shaped_MI_')+'.pdf',bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
